{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = 'Crop_Database.csv'  # Replace with the correct file path\n",
    "data = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA: Handling missing values\n",
    "data = data.assign(\n",
    "    temperature=data['temperature'].fillna(data['temperature'].mean()),\n",
    "    humidity=data['humidity'].fillna(data['humidity'].mean()),\n",
    "    rainfall=data['rainfall'].fillna(data['rainfall'].mean())\n",
    ")\n",
    "\n",
    "data = data.dropna(subset=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical labels (assuming the label is categorical)\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "features = ['temperature', 'humidity', 'rainfall']\n",
    "data[features] = scaler.fit_transform(data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the training dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "y_pred_rf = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8873\n",
      "Random Forest Precision: 0.8941\n",
      "Random Forest Recall: 0.8873\n",
      "Random Forest F1 Score: 0.8868\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84        24\n",
      "           1       0.95      0.95      0.95        21\n",
      "           2       0.76      0.90      0.83        21\n",
      "           3       0.91      1.00      0.95        20\n",
      "           4       0.84      0.94      0.89        17\n",
      "           5       0.89      0.89      0.89        19\n",
      "           6       0.86      0.90      0.88        20\n",
      "           7       0.71      0.71      0.71         7\n",
      "           8       1.00      0.85      0.92        27\n",
      "           9       1.00      1.00      1.00        15\n",
      "          10       0.88      0.78      0.82        18\n",
      "          11       0.76      1.00      0.86        19\n",
      "          12       0.79      0.83      0.81        18\n",
      "          13       1.00      0.93      0.97        15\n",
      "          14       1.00      1.00      1.00        22\n",
      "          15       0.90      0.73      0.81        26\n",
      "          16       1.00      0.80      0.89        15\n",
      "          17       0.85      0.65      0.74        26\n",
      "          18       0.73      0.84      0.78        19\n",
      "          19       1.00      1.00      1.00        22\n",
      "          20       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           0.89       417\n",
      "   macro avg       0.89      0.89      0.88       417\n",
      "weighted avg       0.89      0.89      0.89       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "classification_rep_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"Random Forest Precision: {precision_rf:.4f}\")\n",
    "print(f\"Random Forest Recall: {recall_rf:.4f}\")\n",
    "print(f\"Random Forest F1 Score: {f1_rf:.4f}\")\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", classification_rep_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "xgb_classifier.fit(X_train_smote, y_train_smote)\n",
    "y_pred_xgb = xgb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8681\n",
      "XGBoost Precision: 0.8724\n",
      "XGBoost Recall: 0.8681\n",
      "XGBoost F1 Score: 0.8678\n",
      "\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71        24\n",
      "           1       0.95      1.00      0.98        21\n",
      "           2       0.78      0.86      0.82        21\n",
      "           3       0.91      1.00      0.95        20\n",
      "           4       0.80      0.94      0.86        17\n",
      "           5       0.90      0.95      0.92        19\n",
      "           6       0.95      0.90      0.92        20\n",
      "           7       0.78      1.00      0.88         7\n",
      "           8       0.96      0.85      0.90        27\n",
      "           9       1.00      0.87      0.93        15\n",
      "          10       0.80      0.67      0.73        18\n",
      "          11       0.77      0.89      0.83        19\n",
      "          12       0.74      0.78      0.76        18\n",
      "          13       1.00      0.93      0.97        15\n",
      "          14       1.00      1.00      1.00        22\n",
      "          15       0.77      0.77      0.77        26\n",
      "          16       0.92      0.73      0.81        15\n",
      "          17       0.86      0.73      0.79        26\n",
      "          18       0.71      0.79      0.75        19\n",
      "          19       1.00      0.95      0.98        22\n",
      "          20       0.96      1.00      0.98        26\n",
      "\n",
      "    accuracy                           0.87       417\n",
      "   macro avg       0.87      0.87      0.87       417\n",
      "weighted avg       0.87      0.87      0.87       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb, average='weighted')\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb, average='weighted')\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "classification_rep_xgb = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(f\"XGBoost Precision: {precision_xgb:.4f}\")\n",
    "print(f\"XGBoost Recall: {recall_xgb:.4f}\")\n",
    "print(f\"XGBoost F1 Score: {f1_xgb:.4f}\")\n",
    "print(\"\\nXGBoost Classification Report:\\n\", classification_rep_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Ensemble Model\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('xgb', XGBClassifier(random_state=42))\n",
    "]\n",
    "meta_model = LogisticRegression()\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "stacking_model.fit(X_train_smote, y_train_smote)\n",
    "y_pred_stacking = stacking_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model Accuracy: 0.8849\n",
      "Stacking Model Precision: 0.8891\n",
      "Stacking Model Recall: 0.8849\n",
      "Stacking Model F1 Score: 0.8847\n",
      "\n",
      "Stacking Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82        24\n",
      "           1       0.95      0.95      0.95        21\n",
      "           2       0.76      0.90      0.83        21\n",
      "           3       0.91      1.00      0.95        20\n",
      "           4       0.80      0.94      0.86        17\n",
      "           5       0.90      0.95      0.92        19\n",
      "           6       0.86      0.95      0.90        20\n",
      "           7       0.86      0.86      0.86         7\n",
      "           8       0.96      0.85      0.90        27\n",
      "           9       1.00      0.87      0.93        15\n",
      "          10       0.81      0.72      0.76        18\n",
      "          11       0.77      0.89      0.83        19\n",
      "          12       0.82      0.78      0.80        18\n",
      "          13       1.00      0.93      0.97        15\n",
      "          14       1.00      1.00      1.00        22\n",
      "          15       0.80      0.77      0.78        26\n",
      "          16       1.00      0.80      0.89        15\n",
      "          17       0.86      0.73      0.79        26\n",
      "          18       0.80      0.84      0.82        19\n",
      "          19       1.00      1.00      1.00        22\n",
      "          20       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           0.88       417\n",
      "   macro avg       0.89      0.88      0.88       417\n",
      "weighted avg       0.89      0.88      0.88       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Stacking Model\n",
    "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
    "precision_stacking = precision_score(y_test, y_pred_stacking, average='weighted')\n",
    "recall_stacking = recall_score(y_test, y_pred_stacking, average='weighted')\n",
    "f1_stacking = f1_score(y_test, y_pred_stacking, average='weighted')\n",
    "classification_rep_stacking = classification_report(y_test, y_pred_stacking)\n",
    "\n",
    "print(f\"Stacking Model Accuracy: {accuracy_stacking:.4f}\")\n",
    "print(f\"Stacking Model Precision: {precision_stacking:.4f}\")\n",
    "print(f\"Stacking Model Recall: {recall_stacking:.4f}\")\n",
    "print(f\"Stacking Model F1 Score: {f1_stacking:.4f}\")\n",
    "print(\"\\nStacking Model Classification Report:\\n\", classification_rep_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best model and preprocessing objects\n",
    "joblib.dump(stacking_model, 'stacking_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
